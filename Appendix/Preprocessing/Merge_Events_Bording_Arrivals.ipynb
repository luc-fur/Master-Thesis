{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "pd.options.display.max_rows\n",
    "\n",
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to lag\n",
    "\n",
    "def buildLaggedFeatures(s,columns, lag=5,dropna=True): #lag=3\n",
    "    '''\n",
    "    From http://stackoverflow.com/questions/20410312/how-to-create-a-lagged-data-structure-using-pandas-dataframe\n",
    "    Builds a new DataFrame to facilitate regressing over all possible lagged features\n",
    "    '''\n",
    "    if type(s) is pd.DataFrame:\n",
    "        new_dict={}\n",
    "        for c in s.columns:\n",
    "            new_dict[c]=s[c]\n",
    "        for col_name in columns:\n",
    "            new_dict[col_name]=s[col_name]\n",
    "            # create lagged Series\n",
    "            for l in range(1,lag+1):\n",
    "                new_dict['%s_lag%d' %(col_name,l)]=s[col_name].shift(l)\n",
    "        res=pd.DataFrame(new_dict,index=s.index)\n",
    "\n",
    "    elif type(s) is pd.Series:\n",
    "        the_range=range(lag+1)\n",
    "        res=pd.concat([s.shift(i) for i in the_range],axis=1)\n",
    "        res.columns=['lag_%d' %i for i in the_range]\n",
    "    else:\n",
    "        print('Only works for DataFrame or Series')\n",
    "        return None\n",
    "    if dropna:\n",
    "        return res.dropna()\n",
    "    else:\n",
    "        return res \n",
    "\n",
    "\n",
    "#function to set in each row if there is an event in the 4h before \n",
    "    \n",
    "\n",
    "\n",
    "def check_ev_diff(ev,df):\n",
    "    for i in range(200):\n",
    "\n",
    "        print(\"---------------------------------------------------\")\n",
    "        print(len(df))\n",
    "\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        for bo_index, bo_row in df.iterrows():\n",
    "            for e_index, e_row in ev.iterrows():\n",
    "                if e_row.starting_time.day == bo_row.TimeStep.day and e_row.starting_time.month == bo_row.TimeStep.month and e_row.starting_time.year == bo_row.TimeStep.year:\n",
    "\n",
    "                    diff= e_row.starting_time - bo_row.TimeStep\n",
    "                    diff = diff.total_seconds() / 3600 \n",
    "                        \n",
    "                    print(diff)\n",
    "                    print(e_row.starting_time)\n",
    "                    print(bo_row.TimeStep)\n",
    "                    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bording  = pd.read_csv(\"Files/BusArrBord/RK_Boardings_2017.csv\", sep=';',decimal=',')\n",
    "alightings  = pd.read_csv(\"Files/BusArrBord/RK_Alightings_2017.csv\", sep=';',decimal=',')\n",
    "\n",
    "bording['TimeStep']=pd.to_datetime(bording['TimeStep'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "alightings['TimeStep']=pd.to_datetime(alightings['TimeStep'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "stop_point = pd.read_csv(\"Files/Poi_StopPoint_1km.csv\", sep=';',decimal=',')\n",
    "venue_poi=stop_point['PoiName'].unique()\n",
    "stop_point=stop_point[['PoiName', 'StopPointId', 'Distance']]\n",
    "stop_point=stop_point[stop_point['StopPointId']<8000000]\n",
    "stop_point=stop_point[stop_point['StopPointId']!=10737]\n",
    "\n",
    "# selecting the closest stops\n",
    "list_closest_stops=[]\n",
    "n=3          #number of closest stops to consider\n",
    "for ven in venue_poi:\n",
    "    only_one=stop_point[stop_point['PoiName']==ven]\n",
    "    only_one.sort_values(by='Distance',inplace=True)\n",
    "    for i in range(n):\n",
    "        list_closest_stops.append(only_one.iloc[i])\n",
    "\n",
    "list_closest_stops_df=pd.DataFrame(list_closest_stops)\n",
    "\n",
    "# Opening events datasets\n",
    "events17=pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\events\\\\READY\\\\Event_with_topics_label.csv\",encoding='latin-1'      )\n",
    "events17['starting_time']=pd.to_datetime(events17['starting_time'],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "events17['end_time']=pd.to_datetime(events17['end_time'],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    \n",
    "#merge bording and stops\n",
    "bord_st_merged=pd.merge(bording, list_closest_stops_df, how='outer', on='StopPointId')\n",
    "bord_st_merged=bord_st_merged.dropna(subset=['PoiName'])\n",
    "bord_st_merged=bord_st_merged[bord_st_merged['BoardingPassengerCount']>0]\n",
    "\n",
    "ali_st_merged=pd.merge(alightings, list_closest_stops_df, how='outer', on='StopPointId')\n",
    "ali_st_merged=ali_st_merged.dropna(subset=['PoiName'])\n",
    "ali_st_merged=ali_st_merged[ali_st_merged['AlightingPassengerCount']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoiName</th>\n",
       "      <th>StopPointId</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28000</td>\n",
       "      <td>297.093086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28005</td>\n",
       "      <td>299.084817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>27999</td>\n",
       "      <td>299.715360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28004</td>\n",
       "      <td>312.943781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28002</td>\n",
       "      <td>317.730171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28006</td>\n",
       "      <td>320.321621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>46742</td>\n",
       "      <td>327.383643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>52890</td>\n",
       "      <td>337.900355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>45842</td>\n",
       "      <td>439.282349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>2747</td>\n",
       "      <td>499.307555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>867</td>\n",
       "      <td>677.057196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>892</td>\n",
       "      <td>682.332524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>893</td>\n",
       "      <td>686.132128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>868</td>\n",
       "      <td>697.604039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28008</td>\n",
       "      <td>712.111684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>28007</td>\n",
       "      <td>754.298858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>894</td>\n",
       "      <td>777.087123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>866</td>\n",
       "      <td>798.443057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>29328</td>\n",
       "      <td>805.333798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>30940</td>\n",
       "      <td>831.318572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>30467</td>\n",
       "      <td>848.819178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>46743</td>\n",
       "      <td>860.943766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>49932</td>\n",
       "      <td>871.715156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>10755</td>\n",
       "      <td>953.968053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>891</td>\n",
       "      <td>956.450196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bella Center</td>\n",
       "      <td>2666</td>\n",
       "      <td>973.891501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PoiName  StopPointId    Distance\n",
       "0   Bella Center        28000  297.093086\n",
       "1   Bella Center        28005  299.084817\n",
       "2   Bella Center        27999  299.715360\n",
       "3   Bella Center        28004  312.943781\n",
       "4   Bella Center        28002  317.730171\n",
       "5   Bella Center        28006  320.321621\n",
       "6   Bella Center        46742  327.383643\n",
       "8   Bella Center        52890  337.900355\n",
       "9   Bella Center        45842  439.282349\n",
       "10  Bella Center         2747  499.307555\n",
       "11  Bella Center          867  677.057196\n",
       "12  Bella Center          892  682.332524\n",
       "13  Bella Center          893  686.132128\n",
       "14  Bella Center          868  697.604039\n",
       "15  Bella Center        28008  712.111684\n",
       "16  Bella Center        28007  754.298858\n",
       "17  Bella Center          894  777.087123\n",
       "18  Bella Center          866  798.443057\n",
       "19  Bella Center        29328  805.333798\n",
       "20  Bella Center        30940  831.318572\n",
       "21  Bella Center        30467  848.819178\n",
       "22  Bella Center        46743  860.943766\n",
       "23  Bella Center        49932  871.715156\n",
       "26  Bella Center        10755  953.968053\n",
       "27  Bella Center          891  956.450196\n",
       "29  Bella Center         2666  973.891501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_point[stop_point['PoiName']==stop_point.PoiName.unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######SELECT\n",
    "venue_names=['Parken', 'Vega', 'Forum', 'Bella Center', 'Royal Arena','DR Koncerthuset']\n",
    "venue_names2= [ 'TeliaParken', 'Vega', 'ForumCopenhagen','BellaCenter',  'RoyalArena','DrKoncerthuset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_df_per_venue=[]\n",
    "for ven_nam in venue_names:\n",
    "    df_per_ven=bord_st_merged[bord_st_merged['PoiName']==ven_nam]\n",
    "    list_df_per_venue.append(df_per_ven)\n",
    "    \n",
    "#create event of event per each venue\n",
    "list_ev_per_venue=[]\n",
    "for ven_nam in venue_names2:\n",
    "    ev_per_ven=events17[events17['venue_unique']==ven_nam]\n",
    "    list_ev_per_venue.append(ev_per_ven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'end_time', 'eventname', 'starting_time', 'venue_unique',\n",
       "       'Music', 'Alternative&Punk_Music', 'Business', 'Children',\n",
       "       'Classic_Music', 'Classical_Music', 'Culture', 'Design', 'Education',\n",
       "       'Electronica_Music', 'Entertainment', 'Football', 'Fælledparken',\n",
       "       'Indipendent_Music', 'Lifestyle', 'Medicine', 'Metal_Music', 'Music.1',\n",
       "       'Pop_Music', 'Religious_Music', 'Rock_Music', 'Sport',\n",
       "       'StageMusicals_Music', 'Traditional_Music', 'Urban_Music',\n",
       "       'entertainment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events17.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_array=events17[['Music', 'Alternative&Punk_Music', 'Business', 'Children',\n",
    "       'Classic_Music', 'Classical_Music', 'Culture', 'Design', 'Education',\n",
    "       'Electronica_Music', 'Entertainment', 'Football', 'Fælledparken',\n",
    "       'Indipendent_Music', 'Lifestyle', 'Medicine', 'Metal_Music', 'Music.1',\n",
    "       'Pop_Music', 'Religious_Music', 'Rock_Music', 'Sport',\n",
    "       'StageMusicals_Music', 'Traditional_Music', 'Urban_Music',\n",
    "       'entertainment']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "7257\n",
      "0\n",
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "24258\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "---------------------------------------------------\n",
      "25261\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "---------------------------------------------------\n",
      "20112\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "---------------------------------------------------\n",
      "6277\n",
      "0\n",
      "5000\n",
      "---------------------------------------------------\n",
      "12295\n",
      "0\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#create df of event per each venue\n",
    "list_df_per_venue=[]\n",
    "for ven_nam in venue_names:\n",
    "    df_per_ven=bord_st_merged[bord_st_merged['PoiName']==ven_nam]\n",
    "    list_df_per_venue.append(df_per_ven)\n",
    "    \n",
    "#create event of event per each venue\n",
    "list_ev_per_venue=[]\n",
    "for ven_nam in venue_names2:\n",
    "    ev_per_ven=events17[events17['venue_unique']==ven_nam]\n",
    "    list_ev_per_venue.append(ev_per_ven)\n",
    "\n",
    "#use the event dataset to check when there are the event\n",
    "df_ult_list_bo=[]\n",
    "\n",
    "for i in range(6): ####################change\n",
    "    df=list_df_per_venue[i]\n",
    "    ev=list_ev_per_venue[i]\n",
    "    \n",
    "    event_1h_bef= np.zeros((len(df,)))\n",
    "    event_2h_bef= np.zeros((len(df,)))\n",
    "    event_3h_bef= np.zeros((len(df,)))\n",
    "\n",
    "    event_during= np.zeros((len(df,)))\n",
    "    \n",
    "    event_1h_aft= np.zeros((len(df,)))\n",
    "    event_2h_aft= np.zeros((len(df,)))\n",
    "    event_3h_aft= np.zeros((len(df,)))\n",
    "    \n",
    "    Time_difference=[9999999999 for x in range(len(df))]\n",
    "    \n",
    "    topic=np.zeros((len(df,),26))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(len(df))\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for bo_index, bo_row in df.iterrows():\n",
    "        if bo_index %5000==0:\n",
    "            print(bo_index)\n",
    "                \n",
    "        for e_index, e_row in ev.iterrows():\n",
    "           \n",
    "            if e_row.starting_time.day == bo_row.TimeStep.day and e_row.starting_time.month == bo_row.TimeStep.month and e_row.starting_time.year == bo_row.TimeStep.year:\n",
    "                \n",
    "                diff= e_row.starting_time - bo_row.TimeStep\n",
    "                diff = diff.total_seconds() / 3600 \n",
    "                \n",
    "                if diff >0 and diff < 3:\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    " \n",
    "                if Time_difference[bo_index]>diff:\n",
    "                    Time_difference[bo_index]=diff\n",
    "\n",
    "                if diff > 0 and diff <= 1:\n",
    "                    event_1h_bef[bo_index] = 1\n",
    "\n",
    "                elif diff > 1 and diff <= 2:\n",
    "                    event_2h_bef[bo_index] = 1\n",
    "\n",
    "                elif diff > 2 and diff <= 3:\n",
    "                    event_3h_bef[bo_index] = 1\n",
    "\n",
    "                diff= e_row.end_time - bo_row.TimeStep\n",
    "                diff = diff.total_seconds() / 3600 \n",
    "                \n",
    "                if diff <=0 and diff >=-3:\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    "                \n",
    "                if diff <= 0 and diff >=-1:\n",
    "                    event_1h_aft[bo_index] = 1\n",
    "                    \n",
    "                elif diff < -1 and diff >=-2:\n",
    "                    event_2h_aft[bo_index] = 1\n",
    "                    \n",
    "                elif diff < -2 and diff >=-3:\n",
    "                    event_3h_aft[bo_index] = 1\n",
    "                \n",
    "                if bo_row.TimeStep>e_row.starting_time and bo_row.TimeStep<e_row.end_time:\n",
    "                    event_during[bo_index]=1\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    "\n",
    "\n",
    "    df['event_1h_bef']=event_1h_bef\n",
    "    df['event_2h_bef']=event_2h_bef\n",
    "    df['event_3h_bef']=event_3h_bef\n",
    "\n",
    "    df['event_1h_aft']=event_1h_aft\n",
    "    df['event_2h_aft']=event_2h_aft\n",
    "    df['event_3h_aft']=event_3h_aft\n",
    "\n",
    "    \n",
    "    df['Time_difference']=Time_difference\n",
    "    \n",
    "    df['event_during']=event_during\n",
    "    \n",
    "    topicDF=pd.DataFrame(topic,columns=[['Music', 'Alternative&Punk_Music', 'Business', 'Children',\n",
    "       'Classic_Music', 'Classical_Music', 'Culture', 'Design', 'Education',\n",
    "       'Electronica_Music', 'Entertainment', 'Football', 'Fælledparken',\n",
    "       'Indipendent_Music', 'Lifestyle', 'Medicine', 'Metal_Music', 'Music.1',\n",
    "       'Pop_Music', 'Religious_Music', 'Rock_Music', 'Sport',\n",
    "       'StageMusicals_Music', 'Traditional_Music', 'Urban_Music',\n",
    "       'entertainment']])\n",
    "\n",
    "    df_t=pd.concat([df,topicDF],axis=1)\n",
    "\n",
    "    \n",
    "    df_ult_list_bo.append(df_t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lag boarding  by stop\n",
    "df_all=pd.concat(df_ult_list_bo)\n",
    "list_stopID=df_all.StopPointId.unique()\n",
    "list_df_per_stop=[]\n",
    "for stopID in list_stopID:\n",
    "    df_per_stop=df_all[df_all['StopPointId']==stopID]\n",
    "    list_df_per_stop.append(df_per_stop)\n",
    "\n",
    "list_df_lagged=[]\n",
    "for df in list_df_per_stop:\n",
    "    df_lagged=buildLaggedFeatures(df, ['BoardingPassengerCount'])\n",
    "    list_df_lagged.append(df_lagged)\n",
    "\n",
    "#put togetther \n",
    "df_final=pd.concat(list_df_lagged)\n",
    "df_final.sort_values(by='TimeStep',inplace=True)\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#datatime\n",
    "df_final[\"day\"] = df_final[\"TimeStep\"].dt.weekday\n",
    "df_final[\"hours\"] = df_final[\"TimeStep\"].dt.hour\n",
    "ho=np.array(pd.get_dummies(df_final[\"hours\"]))\n",
    "ho=pd.DataFrame(ho)\n",
    "df_final=pd.concat([df_final, ho], axis=1)\n",
    "df_final['isWeekend']=df_final['day'].apply(lambda x: x>4)\n",
    "df_final['isWeekend']=df_final['isWeekend']*1\n",
    "\n",
    "#rename column of hour\n",
    "dfs_new=[]\n",
    "dfs_new.append(df_final)\n",
    "for i in range(24):\n",
    "    df_old=dfs_new[i]\n",
    "    df_new=df_old.rename(index=str, columns={i: \"h_%s\"%(i)})\n",
    "    dfs_new.append(df_new)\n",
    "    \n",
    "fin_df=dfs_new[24]\n",
    "\n",
    "\n",
    "#save\n",
    "fin_df.to_pickle(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\FinalDFs\\\\Boarding_2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wheather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col=[\"Temp. (Â°C)high\",\"Temp. (Â°C)avg\",\"Temp. (Â°C)low\",\"Dew Point (Â°C)high\",\"Dew Point (Â°C)avg\",\"Dew Point (Â°C)low\",\"Humidity (%)high\",\n",
    "\"Humidity (%)avg\",\"Humidity (%)low\",\"Sea Level Press. (hPa)high\",\"Sea Level Press. (hPa)avg\",\"Sea Level Press. (hPa)low\",\"Visibility (km)high\",\n",
    "\"Visibility (km)avg\",\"Visibility (km)low\",\"Wind (km/h)high\",\"Wind (km/h)avg\",\"Wind (km/h)high\",\"Precip. (mm)\",\"Events\"]\n",
    "\n",
    "weathers=[]\n",
    "for i in range(12):\n",
    "    i=i+1\n",
    "    w=pd.read_csv(\"C:/Users/User/Desktop/DTU/Thesis/Python Files/Files/Weather data/w%s.csv\"%(i), names=col,skiprows=[0,1])\n",
    "    weathers.append(w)\n",
    "    \n",
    "fin_df.reset_index(inplace=True,drop=True)\n",
    "fin_df['Precipitation']=None\n",
    "fin_df['Temperature']=None\n",
    "\n",
    "for ind,row in weather.iterrows():\n",
    "    month=row.DateTime.month\n",
    "    day=row.DateTime.day\n",
    "    fin_df['Precipitation'][(fin_df['TimeStep'].dt.month==month) & (fin_df['TimeStep'].dt.day==day) ]=row['Precip. (mm)'] \n",
    "    fin_df['Temperature'][(fin_df['TimeStep'].dt.month==month) & (fin_df['TimeStep'].dt.day==day) ]=row['Temp. (Â°C)avg']        \n",
    "    if day==1:\n",
    "        print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin_df.to_pickle(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\FinalDFs\\\\Boarding_2017_w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "6789\n",
      "0\n",
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "28176\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "---------------------------------------------------\n",
      "24829\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "---------------------------------------------------\n",
      "21242\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "---------------------------------------------------\n",
      "6994\n",
      "0\n",
      "5000\n",
      "---------------------------------------------------\n",
      "12304\n",
      "0\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#create df of event per each venue\n",
    "list_df_per_venue=[]\n",
    "for ven_nam in venue_names:\n",
    "    df_per_ven=ali_st_merged[ali_st_merged['PoiName']==ven_nam]\n",
    "    list_df_per_venue.append(df_per_ven)\n",
    "\n",
    "#create event of event per each venue\n",
    "list_ev_per_venue=[]\n",
    "for ven_nam in venue_names2:\n",
    "    ev_per_ven=events17[events17['venue_unique']==ven_nam]\n",
    "    list_ev_per_venue.append(ev_per_ven)\n",
    "\n",
    "#use the event dataset to check when there are the event\n",
    "df_ult_list_al=[]\n",
    "\n",
    "\n",
    "for i in range(6): ##################change\n",
    "    df=list_df_per_venue[i]\n",
    "    ev=list_ev_per_venue[i]\n",
    "    \n",
    "    event_1h_bef= np.zeros((len(df,)))\n",
    "    event_2h_bef= np.zeros((len(df,)))\n",
    "    event_3h_bef= np.zeros((len(df,)))\n",
    "    \n",
    "    event_1h_aft= np.zeros((len(df,)))\n",
    "    event_2h_aft= np.zeros((len(df,)))\n",
    "    event_3h_aft= np.zeros((len(df,)))\n",
    "    \n",
    "    Time_difference=[9999999999 for x in range(len(df))]\n",
    "    \n",
    "    event_during= np.zeros((len(df,)))\n",
    "    \n",
    "    topic=np.zeros((len(df,),26))\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(len(df))\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for bo_index, bo_row in df.iterrows():\n",
    "        if bo_index %5000==0:\n",
    "            print(bo_index)\n",
    "                \n",
    "        for e_index, e_row in ev.iterrows():\n",
    "           \n",
    "            if e_row.starting_time.day == bo_row.TimeStep.day and e_row.starting_time.month == bo_row.TimeStep.month and e_row.starting_time.year == bo_row.TimeStep.year:\n",
    "                \n",
    "                diff= e_row.starting_time - bo_row.TimeStep\n",
    "                diff = diff.total_seconds() / 3600 \n",
    "                \n",
    "                if diff >0 and diff < 3:\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    " \n",
    "                if Time_difference[bo_index]>diff:\n",
    "                    Time_difference[bo_index]=diff\n",
    "\n",
    "                if diff > 0 and diff <= 1:\n",
    "                    event_1h_bef[bo_index] = 1\n",
    "\n",
    "                elif diff > 1 and diff <= 2:\n",
    "                    event_2h_bef[bo_index] = 1\n",
    "\n",
    "                elif diff > 2 and diff <= 3:\n",
    "                    event_3h_bef[bo_index] = 1\n",
    "\n",
    "                diff= e_row.end_time - bo_row.TimeStep\n",
    "                diff = diff.total_seconds() / 3600 \n",
    "                \n",
    "                if diff <=0 and diff >=-3:\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    "                \n",
    "                if diff <= 0 and diff >=-1:\n",
    "                    event_1h_aft[bo_index] = 1\n",
    "                    \n",
    "                elif diff < -1 and diff >=-2:\n",
    "                    event_2h_aft[bo_index] = 1\n",
    "                    \n",
    "                elif diff < -2 and diff >=-3:\n",
    "                    event_3h_aft[bo_index] = 1\n",
    "                \n",
    "                if bo_row.TimeStep>e_row.starting_time and bo_row.TimeStep<e_row.end_time:\n",
    "                    event_during[bo_index]=1\n",
    "                    topic[bo_index]=topics_array[e_index]\n",
    "\n",
    "    df['event_1h_bef']=event_1h_bef\n",
    "    df['event_2h_bef']=event_2h_bef\n",
    "    df['event_3h_bef']=event_3h_bef\n",
    "\n",
    "    df['event_1h_aft']=event_1h_aft\n",
    "    df['event_2h_aft']=event_2h_aft\n",
    "    df['event_3h_aft']=event_3h_aft\n",
    "\n",
    "    \n",
    "    df['Time_difference']=Time_difference\n",
    "    \n",
    "    df['event_during']=event_during\n",
    "    \n",
    "    topicDF=pd.DataFrame(topic,columns=[['Music', 'Alternative&Punk_Music', 'Business', 'Children',\n",
    "       'Classic_Music', 'Classical_Music', 'Culture', 'Design', 'Education',\n",
    "       'Electronica_Music', 'Entertainment', 'Football', 'Fælledparken',\n",
    "       'Indipendent_Music', 'Lifestyle', 'Medicine', 'Metal_Music', 'Music.1',\n",
    "       'Pop_Music', 'Religious_Music', 'Rock_Music', 'Sport',\n",
    "       'StageMusicals_Music', 'Traditional_Music', 'Urban_Music',\n",
    "       'entertainment']])\n",
    "\n",
    "    df_t=pd.concat([df,topicDF],axis=1)\n",
    "\n",
    "    \n",
    "    df_ult_list_al.append(df_t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lag dwell second by stop\n",
    "df_all=pd.concat(df_ult_list_al)\n",
    "list_stopID=df_all.StopPointId.unique()\n",
    "list_df_per_stop=[]\n",
    "for stopID in list_stopID:\n",
    "    df_per_stop=df_all[df_all['StopPointId']==stopID]\n",
    "    list_df_per_stop.append(df_per_stop)\n",
    "\n",
    "list_df_lagged=[]\n",
    "for df in list_df_per_stop:\n",
    "    df_lagged=buildLaggedFeatures(df, ['AlightingPassengerCount'])\n",
    "    list_df_lagged.append(df_lagged)\n",
    "\n",
    "#put togetther \n",
    "df_final=pd.concat(list_df_lagged)\n",
    "df_final.sort_values(by='TimeStep',inplace=True)\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#datatime\n",
    "df_final[\"day\"] = df_final[\"TimeStep\"].dt.weekday\n",
    "df_final[\"hours\"] = df_final[\"TimeStep\"].dt.hour\n",
    "ho=np.array(pd.get_dummies(df_final[\"hours\"]))\n",
    "ho=pd.DataFrame(ho)\n",
    "df_final=pd.concat([df_final, ho], axis=1)\n",
    "df_final['isWeekend']=df_final['day'].apply(lambda x: x>4)\n",
    "df_final['isWeekend']=df_final['isWeekend']*1\n",
    "\n",
    "#rename column of hour\n",
    "dfs_new=[]\n",
    "dfs_new.append(df_final)\n",
    "for i in range(24):\n",
    "    df_old=dfs_new[i]\n",
    "    df_new=df_old.rename(index=str, columns={i: \"h_%s\"%(i)})\n",
    "    dfs_new.append(df_new)\n",
    "    \n",
    "fin_df_al=dfs_new[24]\n",
    "\n",
    "#distance betweeen venue and the nearest train station\n",
    "\n",
    "#save\n",
    "fin_df_al.to_pickle(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\FinalDFs\\\\Alighting_2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main dataset\n",
    "f1 = open(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\FinalDFs\\\\Alighting_2017\", 'rb')\n",
    "fin_df = pickle.load(f1)\n",
    "f1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "fin_df.reset_index(inplace=True,drop=True)\n",
    "fin_df['Precipitation']=None\n",
    "fin_df['Temperature']=None\n",
    "\n",
    "for ind,row in weather.iterrows():\n",
    "    month=row.DateTime.month\n",
    "    day=row.DateTime.day\n",
    "    fin_df['Precipitation'][(fin_df['TimeStep'].dt.month==month) & (fin_df['TimeStep'].dt.day==day) ]=row['Precip. (mm)'] \n",
    "    fin_df['Temperature'][(fin_df['TimeStep'].dt.month==month) & (fin_df['TimeStep'].dt.day==day) ]=row['Temp. (Â°C)avg']        \n",
    "    if day==1:\n",
    "        print(month)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin_df.to_pickle(\"C:\\\\Users\\\\User\\\\Desktop\\\\DTU\\\\Thesis\\\\Python Files\\\\Files\\\\FinalDFs\\\\Alighting_2017_w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
